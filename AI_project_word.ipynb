{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09cfe998-0f16-4470-acbb-953f1446f4f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b56aa58-8bf6-427c-b368-71fbc9a50ec1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\relee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "path_to_file = r\"C:\\Users\\relee\\OneDrive\\Desktop\\science-textbook-grade-5.txt\"\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "013e77c6-6e5e-4543-ba73-8603b60d6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory where checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Checkpoint file name pattern\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "# Define callback\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a63d464-4a38-4683-bbd3-d619cfd97c5c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 22815\n",
      "Unique words: 5238\n"
     ]
    }
   ],
   "source": [
    "# Read the text file\n",
    "try:\n",
    "    with open(path_to_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "except UnicodeDecodeError:\n",
    "    with open(path_to_file, 'r', encoding='latin-1') as f:\n",
    "        text = f.read()\n",
    "\n",
    "text = re.sub(r'\\n+', ' ', text)             # remove newlines\n",
    "text = re.sub(r'[^a-zA-Z0-9 .,!?\\']+', ' ', text)  # keep only basic punctuation\n",
    "words = text.split()\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "text = ' '.join(filtered_words)\n",
    "text = re.sub(r'\\s+', ' ', text).strip()     # normalize whitespace\n",
    "\n",
    "# Tokenize by whitespace\n",
    "words = text.split()\n",
    "\n",
    "# Create vocabulary of unique words\n",
    "vocab = sorted(set(words))\n",
    "print(f'Total words: {len(words)}')\n",
    "print(f'Unique words: {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c9092d4-7036-4395-afbd-f3f3a47c5d9f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# StringLookup layers for word IDs\n",
    "ids_from_words = tf.keras.layers.StringLookup(vocabulary=vocab, mask_token=None)\n",
    "words_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_words.get_vocabulary(), invert=True, mask_token=None)\n",
    "\n",
    "# Convert words to IDs\n",
    "all_word_ids = ids_from_words(words)\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_word_ids)\n",
    "\n",
    "# Utility for decoding predictions\n",
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(words_from_ids(ids), separator=' ', axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98d3585f-8ad7-49df-b496-de10ea6ab807",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 20  # word-based sequence length\n",
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "def split_input_target(sequence):\n",
    "    input_seq = sequence[:-1]\n",
    "    target_seq = sequence[1:]\n",
    "    return input_seq, target_seq\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c39c3741-aa93-4e9c-9b8c-37b7f0b96f14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eca59f4b-c8ca-4449-ad7e-799d0516faf1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        if states is None:\n",
    "            # Grab the batch size from the input tensor dynamically\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            states = [tf.zeros((batch_size, self.gru.units))]\n",
    "    \n",
    "        x, new_states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "        return (x, new_states) if return_state else x\n",
    "        \n",
    "vocab_size = len(ids_from_words.get_vocabulary())\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "model = MyModel(vocab_size, embedding_dim, rnn_units)\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1008cb38-b1eb-4dd7-89b5-865bf26f1782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20, 5239)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3924a5f4-9162-4ee0-b484-f62033fd0267",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_model_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_model_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,341,184</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
       "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>))                      │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5239</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,369,975</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │       \u001b[38;5;34m1,341,184\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ ((\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;34m64\u001b[0m,       │       \u001b[38;5;34m3,938,304\u001b[0m │\n",
       "│                                      │ \u001b[38;5;34m1024\u001b[0m))                      │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m5239\u001b[0m)              │       \u001b[38;5;34m5,369,975\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,649,463</span> (40.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,649,463\u001b[0m (40.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,649,463</span> (40.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,649,463\u001b[0m (40.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19527352-c9d0-4b8c-a8ad-7ff9a558c669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - loss: 8.3872\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=1, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "914e2220-f98e-4670-857a-9da720ee3156",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, words_from_ids, ids_from_words, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.words_from_ids = words_from_ids\n",
    "        self.ids_from_words = ids_from_words\n",
    "\n",
    "        # Prevent \"[UNK]\" from being generated\n",
    "        skip_ids = self.ids_from_words(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            values=[-float('inf')] * len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            dense_shape=[len(ids_from_words.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    # REMOVE THIS:\n",
    "    # @tf.function\n",
    "    \n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        input_words = tf.strings.split(inputs)\n",
    "        input_ids = self.ids_from_words(input_words).to_tensor()\n",
    "    \n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states, return_state=True)\n",
    "        predicted_logits = predicted_logits[:, -1, :] / self.temperature\n",
    "        predicted_logits += self.prediction_mask\n",
    "    \n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "        predicted_words = self.words_from_ids(predicted_ids)\n",
    "    \n",
    "        return predicted_words, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e6c42e5-c184-4af6-9c35-a160bbf60e62",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mitochondria is the pumps sailors AO ml removes world. K soaks sugar. satellite\n",
      "\n",
      "________________________________________________________________________________\n",
      "Run time: 0.43857359886169434\n"
     ]
    }
   ],
   "source": [
    "one_step_model = OneStep(model, words_from_ids, ids_from_words)\n",
    "\n",
    "start = time.time()\n",
    "states = None\n",
    "next_input = tf.constant(['the mitochondria is the'])\n",
    "result = [next_input]\n",
    "\n",
    "for _ in range(10):  # generate 100 words\n",
    "    next_input, states = one_step_model.generate_one_step(next_input, states=states)\n",
    "    result.append(next_input)\n",
    "\n",
    "result = tf.strings.join(result, separator=' ')\n",
    "end = time.time()\n",
    "\n",
    "print(result.numpy()[0].decode('utf-8'))\n",
    "print('\\n' + '_'*80)\n",
    "print(f\"Run time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d40855-9081-4cd0-85a2-a7c7b21a838a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
